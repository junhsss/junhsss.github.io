I"¨<p>Q-Learning ê³„ì—´ì˜ ë°©ë²•ë¡ ë“¤ì€ ìµœì ì˜ ì •ì±…ì´ í•  í–‰ë™ì„ ìƒìƒí•œë‹¤.</p>

\[a' = \mathrm{argmax}_a Q(s', a)\]

<p>ê·¸ë ‡ê²Œ ìƒìƒí•œ \(a'\)ë¥¼ ê°€ì§€ê³  \(Q(s, a)\)ì™€ \(r+\gamma \ Q(s', a')\)ê°€ ë¹„ìŠ·í•´ì§€ë„ë¡ í•™ìŠµí•´ ë‚˜ê°„ë‹¤. ê·¸ëŸ°ë° ë¬¸ì œê°€ ìˆë‹¤. ìµœì ì˜ ì •ì±…ì´ í•  í–‰ë™ì„ ìƒìƒí•˜ëŠ” ì£¼ì²´ëŠ” í•™ìŠµ ì¤‘ì¸ ê°€ì¹˜ í•¨ìˆ˜ì´ë‹¤. ê·¸ëŸ¬ë‹ˆ ë‹¹ì—°í•˜ê²Œë„ ì •í™•í•˜ì§€ ì•Šë‹¤. ì´ ì˜¤ë¥˜ê°€ ì–´ë–¤ ë¬¸ì œë¥¼ ì•¼ê¸°í•˜ëŠ”ì§€ ë”°ì ¸ë³´ì.</p>

<h2 id="ë‚™ê´€ì£¼ì˜ì˜-í•¨ì •">ë‚™ê´€ì£¼ì˜ì˜ í•¨ì •</h2>

<p>\(Q\) ê°’ì„ ê·¼ê±°ë¡œ ê°€ì¥ ì¢‹ì€ \(a'\)ë¥¼ ì„ íƒí•œë‹¤.</p>

\[a' = \mathrm{argmax}_a Q(s', a)\]

<p>ê·¸ë ‡ê²Œ ì„ íƒí•œ \(a'\)ë¡œ \(r+\gamma \ Q(s', a')\)ë¥¼ ê³„ì‚°í•´ ì´ê²ƒì´ ë§ˆì¹˜ ì •ë‹µì¸ ì–‘ \(Q(s,a)\)ì™€ ê°€ê¹Œì›Œì§€ê²Œ ë§Œë“ ë‹¤. í•¨ì •ì€ \(a' = \mathrm{argmax}_a Q(s', a)\)ì— ìˆë‹¤. í•œ ê°€ì§€ ì˜ˆì‹œë¥¼ ë“¤ì–´ë³´ì. ê°€ë ¹ ê°€ëŠ¥í•œ í–‰ë™ë“¤ì´ \(a_1,\) \(a_2,\) \(a_3\)ë¡œ ì„¸ ê°€ì§€ì´ê³ , ìµœì  ì •ì±…ì˜ ê°€ì¹˜ í•¨ìˆ˜ê°€ \(s'\)ì—ì„œ ì•„ë˜ì™€ ê°™ë‹¤ê³  í•´ ë³´ì.</p>

\[Q^*(s', a_1)=2.6\]

\[Q^*(s', a_2)=2\]

\[Q^*(s', a_3)=2.5\]

<p>ê·¸ëŸ¬ë‹ˆ \(s'\)ì—ì„œ ìµœì ì˜ ì •ì±…ì€ \(a_1\)ë§Œì„ í•  í…Œë‹¤. ê·¸ ë•Œì˜ ê°€ì¹˜ëŠ” 2.6ì´ë‹¤. ê·¸ëŸ°ë° ë¬¸ì œëŠ” ìš°ë¦¬ê°€ \(Q^*\)ë¥¼ ì•Œì§€ ëª»í•œë‹¤ëŠ”ë° ìˆë‹¤. ì•„ì§ í•™ìŠµ ì¤‘ì´ê¸° ë•Œë¬¸ì¼ ìˆ˜ë„ ìˆì§€ë§Œ ì‹ ê²½ë§ì„ ì´ìš©í•´ \(Q^*\)ë¥¼ ê·¼ì‚¬í•˜ë ¤ í•˜ê³  ìˆëŠ” ìƒí™©ì´ê¸° ë•Œë¬¸ì— ë³¸ì§ˆì ìœ¼ë¡œ ë¶€ì •í™•í•  ìˆ˜ ë°–ì— ì—†ë‹¤. ì•½ê°„ì˜ ì˜¤ì°¨ê°€ ìˆì—ˆë‹¤ê³  í•´ ë³´ì.</p>

\[\hat{Q}(s', a_1)=2.59\]

\[\hat{Q}(s', a_2)=1.7\]

\[\hat{Q}(s', a_3)=2.64\]

<p>\(\hat{Q}\)ë¥¼ ê·¼ê±°ë¡œ íŒë‹¨í•œ ìµœì ì˜ í–‰ë™ì€ \(a_3\)ì´ê³ , ì¶”ì • ê°€ì¹˜ëŠ” \(2.64\)ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ì˜¤ì°¨ê°€ ì—†ì—ˆë‹¤ë©´ ìµœì ì˜ í–‰ë™ì€ \(a_1\)ì´ê³  ê·¸ ë•Œì˜ ê°€ì¹˜ëŠ” \(2.6\)ì´ë¼ ì¶”ì •í–ˆì–´ì•¼ í•œë‹¤. \(Q(s,a)\)ì˜ ì •ë‹µ ì—­í• ì„ í•  \(r+\gamma Q(s', a')\)ê°€ ì°¸ê°’ë³´ë‹¤ í¬ë‹¤ëŠ” ì˜ëª»ëœ íŒë‹¨ì„ í•˜ê²Œ ëœë‹¤. ì´ëŸ¬í•œ í˜„ìƒì„ Maximization Biasë¼ ë¶€ë¥¸ë‹¤. í•­ìƒ ì •ë‹µì„ ì°¸ê°’ë³´ë‹¤ í¬ê²Œ ì¶”ì •í•˜ë‹ˆ \(Q^*\)ê°€ ì „ì²´ì ìœ¼ë¡œ ì°¸ê°’ì— ë¹„í•´ ë†’ê²Œ í•™ìŠµë˜ëŠ” ê²°ê³¼ë¥¼ ì•¼ê¸°í•œë‹¤. ì „ì²´ì ì¸ ì˜¤ì°¨ëŠ” ë‚®ì€ ë°©í–¥ìœ¼ë¡œ ì‘ìš©í–ˆë‹¤. \(a_1\)ê³¼ \(a_2\)ì˜ ê°€ì¹˜ë¥¼ ì°¸ê°’ë³´ë‹¤ ë‚®ê²Œ ì¶”ì •í–ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  Maximization Biasê°€ ë°œìƒí–ˆë‹¤. ì°¸ìœ¼ë¡œ ë¶ˆê³µí‰í•œ ë…€ì„ì´ë‹¤.</p>

<p>Maximization BiasëŠ” ì™œ ë¬¸ì œì¸ê°€? ê·¸ì•¼ ë‹¹ì—°í•˜ë‹¤. í•™ìŠµí•œ \(Q^*\)ê°€ ì°¸ê°’ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì´ë‹¤. ë‹¤ì‹œ ë§í•´ ìµœì ì˜ ì •ì±…ì— ëŒ€í•œ ê°€ì¹˜ í•¨ìˆ˜ê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì´ë‹¤. Q-Learning ê¸°ë°˜ì˜ ë°©ë²•ë¡ ë“¤ì€ ì´ëŸ¬í•œ í¸í–¥ì„ í•´ê²°í•´ ì£¼ëŠ” ë§¤ì»¤ë‹ˆì¦˜ì´ í•„ìš”í•˜ë‹¤.</p>

<p>í¸í–¥ì´ ë°œìƒí•˜ëŠ” ì´ìœ ë¥¼ ìƒê°í•´ë³´ì. \(\hat{Q}\)ëŠ” ë¬´ì—‡ì„ ê·¼ê±°ë¡œ \(a_3\)ì´ ìµœì ì˜ í–‰ë™ì´ë¼ê³  íŒë‹¨í–ˆëŠ”ê°€? ë§ì¥ë‚œ ê°™ì§€ë§Œ \(\hat{Q}\) ìì‹ ì´ë‹¤. ê·¸ëŸ¬ë‹ˆ \(\hat{Q}\)ëŠ” ì–µìš¸í•˜ë‹¤. ìµœì ì˜ í–‰ë™ì„ ë§í•˜ë˜ì„œ ë§í•˜ê³  ê·¸ ê·¼ê±°ë¥¼ ëŒ€ë˜ì„œ ëŒ”ë‹¤. Maximization Biasê°€ ë°œìƒí•˜ëŠ”ê±´ \(\hat{Q}\)ì˜ ì˜ëª»ì´ ì•„ë‹ˆë¼ ê·¸ì € ê·¸ë¥¼ ì˜ëª» ì´ìš©í•˜ê³  ìˆì„ ë¿ì´ë‹¤.</p>

<p>ì˜¤ë²„í”¼íŒ…ì„ ë¹„ìœ ë¡œ ë“¤ ìˆ˜ ìˆê² ë‹¤. í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜¤ì°¨ê°€ ê°€ì¥ ë‚®ì€ ëª¨í˜•ì„ ê³¨ëë‹¤ê³  í•´ ë³´ì. ê·¸ëŸ¬ë©´ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜¤ì°¨ëŠ” ì¼ë°˜ì ì¸ ë°ì´í„°ì— ëŒ€í•œ ì˜¤ì°¨ë³´ë‹¤ ë‹¹ì—°íˆ ë‚®ë‹¤. ê·¸ëŸ¬ë‹ˆ í•™ìŠµ ë°ì´í„°ì™€ ìƒí˜¸ ë°°íƒ€ì ì¸ ê²€ì¦ ë°ì´í„°ë¥¼ ë“¤ê³ ì™€ ëª¨í˜•ì„ ì„ íƒí•œë‹¤.</p>

<p>ë§ˆì°¬ê°€ì§€ë‹¤. \(\hat{Q}\)ì—ê²Œ ìµœì ì˜ í–‰ë™ì„ ë¬¼ì—ˆë‹¤ë©´ ê·¸ê²ƒìœ¼ë¡œ ëë‚´ì•¼ í•œë‹¤. ê·¸ í–‰ë™ì— ëŒ€í•œ ê°€ì¹˜ë¥¼ ë‹¤ì‹œê¸ˆ \(\hat{Q}\)ì—ê²Œ ë¬¼ìœ¼ë©´ ì¦‰ì‹œ Maximization Biasê°€ ë°œìƒí•œë‹¤. \(\hat{Q}\)ê°€ ìµœì ì´ë¼ê³  íŒë‹¨í–ˆë˜ í–‰ë™ì— ëŒ€í•œ ê°€ì¹˜ë¥¼ ì¶”ì •í•´ì¤„ \(\hat{Q}_{\text{other}}\)ê°€ í•„ìš”í•˜ë‹¤. ë°±ë¬¸ì´ ë¶ˆì—¬ì¼ê²¬ì´ë‹¤. ì½”ë“œë¥¼ ë³´ì.</p>

<details id="inside">
<summary>Talk is cheap. Show me the code. â”“ </summary>
<div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">)</span>

<span class="n">STATE_DIM</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">HIDDEN_DIM</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">ACTION_DIM</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">GAMMA</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">EPSILON</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">TAU</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="k">def</span> <span class="nf">to_tensor</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">array</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">maxlen</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">store</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">batch_indices</span><span class="p">]</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="s">'states'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>
                 <span class="s">'actions'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                 <span class="s">'next_states'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>
                 <span class="s">'rewards'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                 <span class="s">'dones'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)}</span>
        <span class="k">return</span> <span class="n">batch</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">)</span>

<span class="n">q1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">STATE_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">ACTION_DIM</span><span class="p">))</span>

<span class="n">q2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">STATE_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">ACTION_DIM</span><span class="p">))</span>

<span class="n">q1_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">q1</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">q2_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">q2</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">LEARNING_RATE</span><span class="p">)</span>

<span class="nb">buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">EPSILON</span><span class="p">:</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">q1</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)).</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
            
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">chosen_action</span><span class="p">)</span>

        <span class="nb">buffer</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">chosen_action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="o">*</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">BATCH_SIZE</span><span class="p">:</span>
        <span class="k">continue</span>
    
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">q1_expected_state_action_values</span> <span class="o">=</span> <span class="n">q1</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s">'actions'</span><span class="p">])</span>
    <span class="n">q2_expected_state_action_values</span> <span class="o">=</span> <span class="n">q2</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s">'actions'</span><span class="p">])</span>

    <span class="n">augmented_next_actions</span> <span class="o">=</span> <span class="n">q1</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'next_states'</span><span class="p">]).</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'rewards'</span><span class="p">]</span> <span class="o">+</span> <span class="n">q2</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'next_states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">augmented_next_actions</span><span class="p">)</span> <span class="o">*</span> <span class="n">GAMMA</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">batch</span><span class="p">[</span><span class="s">'dones'</span><span class="p">])</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">q1_expected_state_action_values</span> <span class="o">-</span> <span class="n">target</span><span class="p">.</span><span class="n">detach</span><span class="p">()).</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span>\
           <span class="p">(</span><span class="n">q2_expected_state_action_values</span> <span class="o">-</span> <span class="n">target</span><span class="p">.</span><span class="n">detach</span><span class="p">()).</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
            
    <span class="n">q1_optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">q2_optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">q1_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">q2_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="s">"""
    for param, param_target in zip(q.parameters(), q_target.parameters()):
        param_target.data.copy_((1-TAU) * param_target.data+ TAU * param.data)
    """</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">performance</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
                <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">q1</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)).</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">chosen_action</span><span class="p">)</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">performance</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="k">print</span><span class="p">(</span><span class="s">f"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">th Trial -&gt; </span><span class="si">{</span><span class="n">performance</span><span class="o">/</span><span class="mi">10</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div>    </div>

  </div>
</details>

<p>\(Q_1\)ì—ê²Œ ìµœì ì˜ í–‰ë™ì„ ê³ ë¥´ê²Œ ë‘ê³ , \(Q_2\)ë¡œ ê·¸ í–‰ë™ì— ëŒ€í•œ ê°€ì¹˜ë¥¼ ì¶”ì •í•˜ê²Œ ë§Œë“ ë‹¤. ê·¸ë ‡ê²Œ ê³„ì‚°í•œ ì •ë‹µìœ¼ë¡œ \(Q_1\)ê³¼ \(Q_2\)ë¥¼ ë™ì‹œì— í•™ìŠµì‹œí‚¨ë‹¤. ë¬¸ì œê°€ ìƒê°ë³´ë‹¤ ê°„ë‹¨íˆ í•´ê²°ëœë‹¤. ì›í•œë‹¤ë©´ \(Q_1\)ê³¼ \(Q_2\)ì´ ì—­í• ì„ ë²ˆê°ˆì•„ ë§¡ë„ë¡ êµ¬í˜„í•´ë„ ëœë‹¤. ììœ ë‹¤.</p>

<p>ì•— ì ê¹. ì§€ë‚œ ì´ì•¼ê¸°ì— ë§ë¯¸ì— ë“±ì¥í–ˆë˜ Target Networkë¥¼ ìŠì—ˆë‹¤. ì›ë˜ì˜ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ì²œì²œíˆ ë”°ë¼ì˜¤ëŠ” Target Networkë¡œ ì •ë‹µì„ ê³„ì‚°í•´ í•™ìŠµì„ ì•ˆì •ì‹œí‚¤ìê³  í–ˆë‹¤. ì´ë¥¼ êµ¬í˜„í•˜ì. ì‹ ê²½ë§ì´ ë‘ ê°œ ìˆì—ˆìœ¼ë‹ˆ Target Networkë¥¼ ê°ê° ë§Œë“¤ì–´ ì£¼ì–´ì•¼ í•œë‹¤. ê·¸ëŸ¬ë‹ˆ ì‹ ê²½ë§ì´ ë„¤ ê°œê°€ ë˜ëŠ” ì…ˆì´ë‹¤.</p>

<details id="inside">
<summary>Talk is cheap. Show me the code. â”“ </summary>
<div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">)</span>

<span class="n">STATE_DIM</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">HIDDEN_DIM</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">ACTION_DIM</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">GAMMA</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">EPSILON</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">TAU</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="k">def</span> <span class="nf">to_tensor</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">array</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">maxlen</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">store</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">batch_indices</span><span class="p">]</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="s">'states'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>
                 <span class="s">'actions'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                 <span class="s">'next_states'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>
                 <span class="s">'rewards'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                 <span class="s">'dones'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)}</span>
        <span class="k">return</span> <span class="n">batch</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">)</span>

<span class="n">q1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">STATE_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">ACTION_DIM</span><span class="p">))</span>

<span class="n">q1_target</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span>

<span class="n">q2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">STATE_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">ACTION_DIM</span><span class="p">))</span>

<span class="n">q2_target</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">q2</span><span class="p">)</span>

<span class="n">q1_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">q1</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="n">q2_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">q2</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">LEARNING_RATE</span><span class="p">)</span>

<span class="nb">buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">EPSILON</span><span class="p">:</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">q1</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)).</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
            
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">chosen_action</span><span class="p">)</span>

        <span class="nb">buffer</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">chosen_action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="o">*</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">BATCH_SIZE</span><span class="p">:</span>
        <span class="k">continue</span>
    
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">q1_expected_state_action_values</span> <span class="o">=</span> <span class="n">q1</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s">'actions'</span><span class="p">])</span>
    <span class="n">q2_expected_state_action_values</span> <span class="o">=</span> <span class="n">q2</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s">'actions'</span><span class="p">])</span>

    <span class="n">augmented_next_actions</span> <span class="o">=</span> <span class="n">q1_target</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'next_states'</span><span class="p">]).</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'rewards'</span><span class="p">]</span> <span class="o">+</span> <span class="n">q2_target</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'next_states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">augmented_next_actions</span><span class="p">)</span> <span class="o">*</span> <span class="n">GAMMA</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">batch</span><span class="p">[</span><span class="s">'dones'</span><span class="p">])</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">q1_expected_state_action_values</span> <span class="o">-</span> <span class="n">target</span><span class="p">.</span><span class="n">detach</span><span class="p">()).</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span>\
           <span class="p">(</span><span class="n">q2_expected_state_action_values</span> <span class="o">-</span> <span class="n">target</span><span class="p">.</span><span class="n">detach</span><span class="p">()).</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
            
    <span class="n">q1_optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">q2_optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">q1_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">q2_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">param_target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">q1</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q1_target</span><span class="p">.</span><span class="n">parameters</span><span class="p">()):</span>
        <span class="n">param_target</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">copy_</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">TAU</span><span class="p">)</span> <span class="o">*</span> <span class="n">param_target</span><span class="p">.</span><span class="n">data</span><span class="o">+</span> <span class="n">TAU</span> <span class="o">*</span> <span class="n">param</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">param_target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">q2</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q2_target</span><span class="p">.</span><span class="n">parameters</span><span class="p">()):</span>
        <span class="n">param_target</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">copy_</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">TAU</span><span class="p">)</span> <span class="o">*</span> <span class="n">param_target</span><span class="p">.</span><span class="n">data</span><span class="o">+</span> <span class="n">TAU</span> <span class="o">*</span> <span class="n">param</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">performance</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
                <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">q1</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)).</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">chosen_action</span><span class="p">)</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">performance</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="k">print</span><span class="p">(</span><span class="s">f"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">th Trial -&gt; </span><span class="si">{</span><span class="n">performance</span><span class="o">/</span><span class="mi">10</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div>    </div>

  </div>
</details>

<p>Q-Learningì—ì„œ ë°œìƒí•˜ëŠ” ì´ëŸ° í¸í–¥ì€ <a href="https://www.ri.cmu.edu/pub_files/pub1/thrun_sebastian_1993_1/thrun_sebastian_1993_1.pdf">ì˜¤ë˜ ì „ë¶€í„° ì•Œë ¤ì ¸ ìˆë˜ í˜„ìƒ</a>ì´ë‹¤.  DQNì—ì„œë„ ë§ˆì°¬ê°€ì§€ë¡œ ì´ëŸ° í˜„ìƒì´ ê´€ì¸¡ë˜ì—ˆê³ , ì–¼ë§ˆ ê°€ì§€ ì•Šì•„ ë”¥ë§ˆì¸ë“œì˜ ì—°êµ¬ìë“¤ì— ì˜í•´ <a href="https://arxiv.org/abs/1509.06461">Double DQN</a>ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì œì•ˆë˜ì—ˆë‹¤. ì´ ë•Œ ì œì•ˆëœ ë°©ë²•ë¡ ì€ ìœ„ì˜ êµ¬í˜„ì²´ë³´ë‹¤ëŠ” ë‹¨ìˆœí•˜ë‹¤. \(Q_2\)ë¥¼ ê·¸ëƒ¥ \(Q_1\)ì˜ Target Networkë¡œ ê°„ì£¼í•˜ëŠ” ê²ƒì´ë‹¤. ì„œë¡œ ì™„ì „íˆ ë‹¤ë¥´ì§€ëŠ” ì•Šì§€ë§Œ ì–´ì¨Œë“  ë‹¤ë¥¸ ì‹ ê²½ë§ì´ë‹¤. ì–´ì°¨í”¼ Target Networkë¼ëŠ” ë‹¤ë¥¸ ì‹ ê²½ë§ì´ ìˆìœ¼ë‹ˆ ìƒˆë¡œìš´ ì‹ ê²½ë§ì„ ë„ì…í•˜ì§„ ë§ìëŠ” ì•„ì´ë””ì–´ë‹¤.</p>

<p>ê·¸ë ‡ê²Œ í•  ìš”ëŸ‰ì´ë¼ë©´ ì§€ë‚œ ì´ì•¼ê¸°ì˜ DQN êµ¬í˜„ì²´ì—ì„œ ë‹¨ í•œ ë‹¨ì–´ë§Œ ì§€ìš°ë©´ ëœë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Double DQNì´ë¼ê³  ë¶€ë¥´ëŠ”ê±´ ì•„ë˜ì˜ êµ¬í˜„ì²´ë‹¤. (ì‚¬ì¡±: ê·¸ëŸ¬ë‚˜ ë” ì¼ë°˜ì ì¸ êµ¬í˜„ì²´ë¥¼ ë§Œë“  ì´ìœ ê°€ ìˆë‹¤. ì´í›„ ì´ì•¼ê¸°í•  TD3, ë‚´ì§€ëŠ” SACì™€ ìœ ì‚¬í•œ êµ¬í˜„ì´ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ëŸ¬ë‹ˆ ì½ê³  ë„˜ê¸°ì ğŸ™…ğŸ»â€â™€ï¸)</p>

<details id="inside">
<summary>Talk is cheap. Show me the code. â”“ </summary>
<div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">"CartPole-v1"</span><span class="p">)</span>

<span class="n">STATE_DIM</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">HIDDEN_DIM</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">ACTION_DIM</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">GAMMA</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">EPSILON</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">TAU</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="k">def</span> <span class="nf">to_tensor</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">array</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">maxlen</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">store</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">batch_indices</span><span class="p">]</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="s">'states'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>
                 <span class="s">'actions'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                 <span class="s">'next_states'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>
                 <span class="s">'rewards'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                 <span class="s">'dones'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)}</span>
        <span class="k">return</span> <span class="n">batch</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">)</span>

<span class="n">q</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">STATE_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">HIDDEN_DIM</span><span class="p">),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_DIM</span><span class="p">,</span> <span class="n">ACTION_DIM</span><span class="p">))</span>

<span class="n">q_target</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">LEARNING_RATE</span><span class="p">)</span>
<span class="nb">buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">EPSILON</span><span class="p">:</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">q</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)).</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
            
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">chosen_action</span><span class="p">)</span>

        <span class="nb">buffer</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">chosen_action</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="o">*</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">BATCH_SIZE</span><span class="p">:</span>
        <span class="k">continue</span>
    
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">expected_state_action_values</span> <span class="o">=</span> <span class="n">q</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s">'actions'</span><span class="p">])</span>

    <span class="n">augmented_next_actions</span> <span class="o">=</span> <span class="n">q</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'next_states'</span><span class="p">]).</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'rewards'</span><span class="p">]</span> <span class="o">+</span> <span class="n">q_target</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s">'next_states'</span><span class="p">]).</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">augmented_next_actions</span><span class="p">)</span> <span class="o">*</span> <span class="n">GAMMA</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">batch</span><span class="p">[</span><span class="s">'dones'</span><span class="p">])</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">expected_state_action_values</span> <span class="o">-</span> <span class="n">target</span><span class="p">.</span><span class="n">detach</span><span class="p">()).</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
    
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">param_target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q_target</span><span class="p">.</span><span class="n">parameters</span><span class="p">()):</span>
        <span class="n">param_target</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">copy_</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">TAU</span><span class="p">)</span> <span class="o">*</span> <span class="n">param_target</span><span class="p">.</span><span class="n">data</span><span class="o">+</span> <span class="n">TAU</span> <span class="o">*</span> <span class="n">param</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">performance</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
                <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">q</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">)).</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">chosen_action</span><span class="p">)</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">performance</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="k">print</span><span class="p">(</span><span class="s">f"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">th Trial -&gt; </span><span class="si">{</span><span class="n">performance</span><span class="o">/</span><span class="mi">10</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div>    </div>

  </div>
</details>

<p>ìš°ë¦¬ì˜ ëª©í‘œëŠ” Offline RLì´ë‹¤. Offline RLì—ì„œëŠ” Maximization Biasê°€ ë” ì•„í”„ê²Œ ë‹¤ê°€ì˜¨ë‹¤.</p>
:ET