I"<p>강화학습에서는 학습 주체를 둘러싸고 있는 주변 환경이 동작하는 원리를 모델이라고 부른다. 이런 상황에서 저런 행위를 했을 때 상황이 어떻게 변하는지 알고 있으면 모델을 알고 있다는 개념이다. 모델을 알고 있으면 무엇이 좋은가? 현재 시점에서 가능한 모든 미래들을 나열하여 그 중 최선일 것으로 사료되는 시나리오를 따라가면 된다. 즉 트리 서치를 하면 된다.  당연하게도 대부분의 상황에서 scalable하게 적용할 수 있는 아이디어는 아니다. (그 닥터 스트레인지조차 고작 천 4백만개 언저리에서 포기하고 말았다.) 그런 상황에서 신경망의 도움을 받아 tree search를 하자는 이야기가 알파고가 차용한 MCTS (Monte Carlo Tree Search)이다. 바둑은 모델을 완전히 알고 있지 않은가? 플레이어가 착점하면 바둑판의 그 위치에 돌이 생기는 자명한 이치가 바로 바둑의 모델이다.</p>
:ET