<!DOCTYPE html>
<html>
  <head>
    <title>JunHyoung Ryu Blog – minimal thoughts</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  
    " />
    <meta property="og:description" content="
  
    " />
    
    <meta name="author" content="JunHyoung Ryu Blog" />

    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="JunHyoung Ryu Blog - minimal thoughts" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="/images/jekyll-logo.png" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">JunHyoung Ryu Blog</a></h1>
            <p class="site-description">minimal thoughts</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <div class="posts">
  
    <article class="post">

      <h1><a href="/Temporal-Difference/">강화 학습 이야기 3</a></h1>

      <div class="entry">
        <p>앞서 이해한 가치 함수의 정의는 직관적이다. 그러나 가치 함수에는 훨씬 강력한 구조가 숨겨져 있다. 상태 가치함수 \(V^{\pi}\)의 경우를 생각해보자. 행위자가 상태 \(s\)에서 행위 \(a\)를 하면 환경으로부터 보상 \(r\)이 주어지고 상태가 \(s'\)로 바뀐다. 그렇다면 원래 상태의 가치 \(V^{\pi}(s)\)와 바뀐 상태의 가치 \(V^{\pi}(s')\) 사이에는 어떤 관계가 존재할까? 두 상태가 시간적으로 매우 가까우므로 크게 다르지 않을 것 같다. 정확히는 현재 상태에서 보상 \(r\)을 받고 다음 상태 \(s'\)로 넘어간 것이니 아마도 아래와 같을 것이다.</p>

      </div>

      <a href="/Temporal-Difference/" class="read-more">더 읽기</a>
    </article>
  
    <article class="post">

      <h1><a href="/Value-Function/">강화 학습 이야기 2</a></h1>

      <div class="entry">
        <p>강화학습에서 가장 핵심적인 양은 가치 함수이다. 그런만큼 잘못 이해하면 인생이 힘들어진다. 언제나 그렇듯 수식이 중요한 것은 아니다. 직관적으로 제대로 이해해보자.</p>

      </div>

      <a href="/Value-Function/" class="read-more">더 읽기</a>
    </article>
  
    <article class="post">

      <h1><a href="/Policy-Gradient/">강화 학습 이야기 1</a></h1>

      <div class="entry">
        <p>대개 신경망 훈련은 트레이닝 데이터에 대한 가능도 (likelihood)를 높이는 방향으로 이루어진다. 고양이라는 제목이 달려있는 픽셀 덩어리가 신경망에 입력되었을 때 신경망이 유도하는 확률 분포에서 고양이에 해당하는 값이 가능도이고, 이 가능도가 늘어나도록 파라미터를 건드리는 것이 소위 신경망 훈련이다.</p>

      </div>

      <a href="/Policy-Gradient/" class="read-more">더 읽기</a>
    </article>
  
    <article class="post">

      <h1><a href="/Not-Hello-World/">모델 기반 강화학습에 대한 단상</a></h1>

      <div class="entry">
        <p>강화학습에서는 학습 주체를 둘러싸고 있는 주변 환경이 동작하는 원리를 모델이라고 부른다. 이런 상황에서 저런 행위를 했을 때 상황이 어떻게 변하는지 알고 있으면 모델을 알고 있다는 개념이다. 모델을 알고 있으면 무엇이 좋은가? 현재 시점에서 가능한 모든 미래들을 나열하여 그 중 최선일 것으로 사료되는 시나리오를 따라가면 된다. 즉 트리 서치를 하면 된다.  당연하게도 대부분의 상황에서 scalable하게 적용할 수 있는 아이디어는 아니다. (그 닥터 스트레인지조차 고작 천 4백만개 언저리에서 포기하고 말았다.) 그런 상황에서 신경망의 도움을 받아 tree search를 하자는 이야기가 알파고가 차용한 MCTS (Monte Carlo Tree Search)이다. 바둑은 모델을 완전히 알고 있지 않은가? 플레이어가 착점하면 바둑판의 그 위치에 돌이 생기는 자명한 이치가 바로 바둑의 모델이다.</p>

      </div>

      <a href="/Not-Hello-World/" class="read-more">더 읽기</a>
    </article>
  
</div>
    </div>
    <!--
    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          



<a href="https://github.com/barryclark/jekyll-now"><i class="svg-icon github"></i></a>




<a href="https://www.twitter.com/jekyllrb"><i class="svg-icon twitter"></i></a>



        </footer>
      </div>
    </div>
    -->

    

  </body>
</html>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>